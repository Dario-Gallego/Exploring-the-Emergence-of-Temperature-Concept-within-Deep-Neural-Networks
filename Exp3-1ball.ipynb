{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# From images to coordinates"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "import keras.backend as K"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:01<00:00, 5964.74it/s]\n",
            "100%|██████████| 10000/10000 [00:01<00:00, 5319.44it/s]\n"
          ]
        }
      ],
      "source": [
        "# Dataset dependant parameters\n",
        "data_path = \"data/1ball/\"\n",
        "num_balls = 1\n",
        "num_systems = 10000\n",
        "color = False\n",
        "pix = 32\n",
        "\n",
        "X1 = []\n",
        "for i in tqdm(glob(data_path + \"Input/image1_*.png\")):\n",
        "    if color:\n",
        "        im = cv2.imread(i)\n",
        "    else:\n",
        "        im = cv2.imread(i, cv2.IMREAD_GRAYSCALE)\n",
        "    im = keras.utils.img_to_array(im)\n",
        "    X1.append(im)\n",
        "X1 = np.array(X1, dtype=\"float32\") / 255\n",
        "\n",
        "X2 = []\n",
        "for i in tqdm(glob(data_path + \"Input/image2_*.png\")):\n",
        "    if color:\n",
        "        im = cv2.imread(i)\n",
        "    else:\n",
        "        im = cv2.imread(i, cv2.IMREAD_GRAYSCALE)\n",
        "    im = keras.utils.img_to_array(im)\n",
        "    X2.append(im)\n",
        "X2 = np.array(X2, dtype=\"float32\") / 255"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Coordinates generation and data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:38<00:00, 256.90it/s]\n"
          ]
        }
      ],
      "source": [
        "coordinates = np.zeros((num_systems, 4*num_balls))\n",
        "\n",
        "for i in tqdm(range(num_systems)):\n",
        "    non_white_x_t0 = []\n",
        "    non_white_y_t0 = []\n",
        "    non_white_x_t1 = []\n",
        "    non_white_y_t1 = []\n",
        "    for j in range(pix):\n",
        "        for k in range(pix):\n",
        "            if X1[i,j,k] != 1:\n",
        "                if j not in non_white_y_t0: non_white_y_t0.append(j)\n",
        "                if k not in non_white_x_t0: non_white_x_t0.append(k)\n",
        "\n",
        "            if X2[i,j,k] != 1:\n",
        "                if j not in non_white_y_t1: non_white_y_t1.append(j)\n",
        "                if k not in non_white_x_t1: non_white_x_t1.append(k)\n",
        "    \n",
        "    coordinates[i] = np.mean(non_white_y_t1), np.mean(non_white_x_t1), np.mean(non_white_x_t1) - np.mean(non_white_x_t0), np.mean(non_white_y_t1) - np.mean(non_white_y_t0)\n",
        "\n",
        "coordinates[:, :2*num_balls] /= pix - 1\n",
        "coordinates[:, 2*num_balls:] /= 4\n",
        "\n",
        "# Concatenate both frames\n",
        "X = np.concatenate((X1, X2), axis=3)\n",
        "# Train-val-test split (80-10-10)\n",
        "x_train, x_test, coordinates_train, coordinates_test = train_test_split(X, coordinates, test_size=0.2)\n",
        "x_val, x_test, coordinates_val, coordinates_test = train_test_split(x_test, coordinates_test, test_size=0.5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model definition and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "izhQ3_w019zW",
        "outputId": "2b126d59-1d3f-477e-aebd-eb776998f206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"ImgToCoordinates\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 2)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 30, 30, 1)         19        \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 1)         10        \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 1, 1, 6)           4710      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12)                84        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 52        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,875\n",
            "Trainable params: 4,875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Input layer\n",
        "inputs = Input(shape=(pix,pix,2 + 4*color))\n",
        "\n",
        "# Hidden layers\n",
        "x = Conv2D(1, (3,3), activation=\"relu\")(inputs)\n",
        "x = Conv2D(1, (3,3), activation=\"relu\")(x)\n",
        "x = Conv2D(6, (28,28), activation=\"relu\")(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(12*num_balls)(x)\n",
        "\n",
        "# Output layer\n",
        "outputs = Dense(4*num_balls)(x)\n",
        "\n",
        "model = Model(inputs, outputs, name=\"ImgToCoordinates\")\n",
        "model.summary()\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 5s 7ms/step - loss: 0.2346 - val_loss: 0.2141\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1961 - val_loss: 0.1730\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1659 - val_loss: 0.1644\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1620 - val_loss: 0.1621\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1601 - val_loss: 0.1604\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.1593 - val_loss: 0.1608\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1580 - val_loss: 0.1590\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1570 - val_loss: 0.1570\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1560 - val_loss: 0.1569\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1557 - val_loss: 0.1563\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1553 - val_loss: 0.1553\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1554 - val_loss: 0.1576\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1551 - val_loss: 0.1557\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1552 - val_loss: 0.1557\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1551 - val_loss: 0.1558\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1549 - val_loss: 0.1557\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1550 - val_loss: 0.1564\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1551 - val_loss: 0.1560\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1547 - val_loss: 0.1564\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1547 - val_loss: 0.1560\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1547 - val_loss: 0.1557\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b4de185fd0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss='mae', optimizer='adam')\n",
        "\n",
        "model.fit(x_train, coordinates_train,\n",
        "                epochs=100,\n",
        "                batch_size=16,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_val, coordinates_val),\n",
        "                callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, min_delta=0.0001)])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 5ms/step\n",
            "0\n",
            "Prediction: [6.7942172e-01 5.4686618e-01 5.1492453e-04 2.2205877e-01]\n",
            "Actual coordinates: [0.67741935 0.5483871  0.5        0.25      ]\n",
            "1\n",
            "Prediction: [ 0.41604063  0.32963115 -0.00115312 -0.11232381]\n",
            "Actual coordinates: [0.41935484 0.35483871 0.         0.5       ]\n",
            "2\n",
            "Prediction: [ 0.22514647  0.7461756   0.0020702  -0.31634507]\n",
            "Actual coordinates: [ 0.22580645  0.74193548  0.         -0.5       ]\n",
            "3\n",
            "Prediction: [ 0.3331149   0.38561282 -0.00071788 -0.20929793]\n",
            "Actual coordinates: [0.32258065 0.38709677 0.25       0.25      ]\n",
            "4\n",
            "Prediction: [ 3.9973035e-01  5.4567945e-01  5.1573664e-04 -1.1770392e-01]\n",
            "Actual coordinates: [ 0.38709677  0.5483871  -0.25        0.25      ]\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(x_test)\n",
        "\n",
        "for i in range(5):\n",
        "    print(str(i) + '\\nPrediction: ' + str(predictions[i]) + '\\nActual coordinates: ' + str(coordinates_test[i]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are getting pretty good predictions in terms of position coordinates but not so with the predictions of the velocity vectors."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "thesis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "63a4dc49e75b3ba52538fc9a96138b714fbb90abc770225ff62782ff75259691"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
